# SUPERVISED MACHINE LEARNING TECHNIQUE: kNN (k Nearest Neighbor Algorithm)

**PROGRAMMING LANGUAGE USED:** Python 3.x

**IDE:** Jupyter

**AIM:**  Use NearestNeighbors to identify neighbours

**TASKS:**
Dataset Used: Athelete Selection 
1. Load the dataset
2. Normalise the data
3. Classify the training data into target classes.
4. Predict the class for an unknown query.
5. Evaluate the performance of the classifier.

**kNN:** K-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm which can be used for both classification as well as regression predictive problems. 
However, it is mainly used for classification predictive problems in industry. 
1. Lazy learning algorithm − KNN is a lazy learning algorithm because it does not have a specialized training phase and uses all the data for training while classification.
2. Non-parametric learning algorithm − KNN is also a non-parametric learning algorithm because it doesn’t assume anything about the underlying data. 

This k-Nearest Neighbors algorithm comprises of 3 steps:
Step 1: Calculate Euclidean Distance.
Step 2: Get Nearest Neighbors.
Step 3: Make Predictions.

![image](https://user-images.githubusercontent.com/38240162/72687375-114ed900-3af5-11ea-8b52-eb7742db8d91.png)

Normalization: Often, raw data is comprised of attributes with varying scales. 
For example, one attribute may be in kilograms and another may be a count. Although not required, you can often get a boost in performance by carefully choosing methods to rescale your data.

Training Data:Training Data is labeled data used to train your machine learning algorithms and increase accuracy.

Test Data:Every machine learning model needs to be tested in the real world to measure how robust its predictions are. This is data that it has never seen before.

**CONCLUSION:** kNN algorithm implementation with Athlete Selection example is shown above.
